# importing library
import pickle  # Reading processed data from the file
import tensorflow as tf
from tensorflow.keras.applications.vgg16 import VGG16
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import Input, Lambda, Flatten, Dense
from keras.utils.vis_utils import plot_model
import pydot  # Used to plot model architecture
import seaborn as sns  # Used to show the counts of observations in each category.
import matplotlib.pyplot as plt  # Used to plot graphs.
from sklearn.metrics import confusion_matrix  # Used to plot confusion matrix.


# Loading preprocessed features
pickle_in = open('./Dataset/X.pickle', 'rb')
X = pickle.load(pickle_in)  # It has Features


# Loading preprocessed labels
pickle_in = open('./Dataset/Y.pickle', 'rb')
Y = pickle.load(pickle_in)  # It has Labels


# Normalizing the data in the range of [0, 1]
X = X / 255.0
print(X)


# Importing VGG16 model with pre-trained weights of imagenet
vgg16 = VGG16(input_shape=[100, 100, 3], weights='imagenet', include_top=False)  # include_top = False --> Remove 1st and last layer of VGG16.
vgg16.summary()


# Do not train existing weights
for layers in vgg16.layers:
    layers.trainable = False  # Using original weights of the VGG16 model, except for 1st & last layers.


# Changing 1st & last layer of the VGG16 model due to two category of data.
Z = Flatten()(vgg16.output)
predictions = Dense(1, activation="sigmoid")(Z)
model = Model(inputs=vgg16.input, outputs=predictions)
model.summary()


# Compiling the model
model.compile(loss="binary_crossentropy", optimizer="adam", metrics=['accuracy'])
model.optimizer.lr = 0.0001


# Training the model
h = model.fit(X, Y, batch_size = 32, epochs = 50, validation_split = 0.3)


# Saving the model.
model.save("./VGG16/VGG16_TL_Model_50.h5")


plot_model(model, to_file='./VGG16/VGG16_Layers.png')


# Plot Accuracy & Loss Graphs
plt.plot(h.history["accuracy"])
plt.plot(h.history['val_accuracy'])
plt.plot(h.history['loss'])
plt.plot(h.history['val_loss'])
plt.title("Loss & Accuracy Model")
plt.xlabel("Epoch")
plt.ylabel("Accuracy")
plt.legend(["Accuracy","Validation Accuracy","Loss","Validation Loss"])
plt.show()
plt.savefig("./VGG16/VGG16_Loss_Accuracy_Graph_50.png")


# Comparing probability with the real labels
plt.plot(model.predict(X),'.',color='red',label='Predicted Probabilty')
plt.plot(Y,'.',color='navy',label='Actual Labels')
plt.xlabel('Total Number of Data')
plt.ylabel('Probability')
plt.legend()
plt.savefig('./VGG16/VGG16_Actual_vs_Predicted_Graph_50.png')
